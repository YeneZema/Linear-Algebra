\documentclass[11pt]{article}
\usepackage{tikz}

\usetikzlibrary{shapes,shadows,positioning,backgrounds}
\usepackage{amsmath,amsfonts,amsthm,amssymb,amscd,xspace}
\usepackage{graphicx,xcolor,lipsum,cancel}
\usepackage[margin=1in]{geometry}
\usepackage[linkcolor=blue]{hyperref}
\hypersetup{pdfborder={0 0 0}, colorlinks=true, urlcolor=blue}
\usepackage{todonotes}
\usepackage{tocloft}
\usepackage{microtype}
\usepackage{palatino}

%%% Headers and footers
\usepackage{fancyhdr}												% Needed to define custom headers/footers
	\pagestyle{fancy}												% Enabling the custom headers/footers
\usepackage{lastpage}	
\usepackage{afterpage}
% Header (empty)
\lhead{}
\chead{}
\rhead{}
% Footer (you may change this to your own needs)
\lfoot{\footnotesize \texttt{www.albohessab.weebly.com} \textbullet ~Miliyon T.}
\cfoot{}
\rfoot{\footnotesize page \thepage\ of \pageref{LastPage}}	% "Page 1 of 2"
\renewcommand{\headrulewidth}{0.0pt}
\renewcommand{\footrulewidth}{0.4pt}
% various theorems, numbered by section
\newtheorem{example}{Example}[section]
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{exmp}[thm]{Example}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}
\newtheorem{rem}[thm]{Remark}
\theoremstyle{plain}
%777777777777777777777777777777


\begin{document}
\clearpage

\title{Matrix Diagonalization}
\author{Miliyon T.}
\maketitle
\section{Introductions}

When we introduced eigenvalues and eigenvectors, we wondered when a square matrix is similarly equivalent to a diagonal matrix? In other words, given a square matrix $A$, does a diagonal matrix $D$ exist such that $A \sim D$? (i.e. there exists an invertible matrix $P$ such that $A = P^{-1}DP$)

\medskip

\noindent In general, some matrices are not similar to diagonal matrices. For example, consider the matrix

\[ A =
\left(\begin{array}{rrr}
2&1\\
0&2\\
\end{array}\right)
\]
Assume there exists a diagonal matrix $D$ such that $A = P^{-1}DP$. Then we have

\[
A - \lambda I_n = P^{-1}DP - \lambda I_n = P^{-1}DP - \lambda P^{-1}P = P^{-1}\Big(D - \lambda I_n \Big)P,
\]
i.e $A - \lambda I_n$ is similar to $D - \lambda I_n$. So they have the same characteristic equation. Hence $A$ and $D$ have the same eigenvalues. Since the eigenvalues of $D$ of the numbers on the diagonal, and the only eigenvalue of $A$ is $2$, then we must have

\[
D = \left(\begin{array}{rrr} 2&0\\ 0&2\\ \end{array}\right) = 2I_2.
\]
In this case, we must have $A = P^{-1}DP = 2 I_2$, which is not the case. Therefore, $A$ is not similar to a diagonal matrix.

\section{Diagonalization}
\begin{defn}
A matrix is diagonalizable if it is similar to a diagonal matrix.
\end{defn}

\begin{rem}
The matrix
\[
A = \left(\begin{array}{rrr} 1&2&1\\ 6&-1&0\\ -1&-2&-1\\ \end{array}\right)
\]
has three different eigenvalues. We also showed that A is diagonalizable. In fact, there is a general result along these lines.
\end{rem}

\begin{thm}
Let $A$ be a square matrix of order $n$. Assume that $A$ has $n$ distinct eigenvalues. Then $A$ is diagonalizable. Moreover, if $P$ is the matrix with the columns $C_1, C_2,\cdots,C_n$ the $n$ eigenvectors of $A$, then the matrix $P^{-1}AP$ is a diagonal matrix. In other words, the matrix $A$ is diagonalizable.
\end{thm}

Problem: What happened to square matrices of order $n$ with less than $n$ eigenvalues?


We have a partial answer to this problem.

\begin{thm}
Let $A$ be a square matrix of order $n$. In order to find out whether $A$ is diagonalizable, we do the following steps:

\begin{enumerate}
  \item Write down the characteristic polynomial
\[
p(\lambda) = \det\Big(A - \lambda I_n\Big).
\]

  \item Factorize $p(\lambda) $. In this step, we should be able to get
\[
p(\lambda) = (\lambda - \lambda_1)^{n_1} \cdot (\lambda - \lambda_2)^{n_2}\cdots (\lambda - \lambda_k)^{n_k}
\]
where the $\lambda_i$, $i=1,\cdots,k$, may be real or complex. For every $i$, the powers $n_i$ is called the (\textbf{algebraic}) multiplicity of the eigenvalue $\lambda_i$.

  \item For every eigenvalue, find the associated eigenvectors. For example, for the eigenvalue $\lambda_i$, the eigenvectors are given by the linear system
\[
A \cdot X = \lambda_i X \;\;\mbox{or}\;\; \Big(A - \lambda_i I_n \Big) X = {\cal O}.
\]
Then solve it. We should find the unknown vector $X$ as a linear combination of vectors, i.e.
\[
X = \alpha_1 C_1 + \alpha_2 C_2 + \cdots + \alpha_{m_i} C_{m_i}
\]
where $\alpha_j$, $j=1,\cdots, m_i$ are arbitrary numbers. The integer $m_i$ is called the \textbf{geometric} multiplicity of $\lambda_i$.

  \item If for every eigenvalue the algebraic multiplicity is equal to the geometric multiplicity, then we have
\[
m_1 + m_2 + \cdots + m_k = n
\]
which implies that if we put the eigenvectors $C_j$, we obtained in $3$. for all the eigenvalues, we get exactly $n$ vectors. Set $P$ to be the square matrix of order $n$ for which the column vectors are the eigenvectors $C_j$. Then $P$ is invertible and
\[
P^{-1}\cdot A \cdot P
\]
is a diagonal matrix with diagonal entries equal to the eigenvalues of $A$. The position of the vectors $C_j$ in $P$ is identical to the position of the associated eigenvalue on the diagonal of $D$. This identity implies that $A$ is similar to $D$. Therefore, $A$ is diagonalizable.
\begin{rem}
If the algebraic multiplicity $n_i$ of the eigenvalue $\lambda_i$ is equal to $1$, then obviously we have $m_i = 1$. In other words, $n_i = m_i$.
\end{rem}

  \item If for some eigenvalue the algebraic multiplicity is not equal to the geometric multiplicity, then $A$ is not diagonalizable.
\end{enumerate}
\end{thm}
\begin{exmp}
Consider the matrix
\[
A = \left(\begin{array}{rrr} -1&-1&1\\ 0&-2&1\\ 0&0&-1\\ \end{array}\right).
\]

In order to find out whether $A$ is diagonalizable, let us follow the steps described above.
\begin{enumerate}
  \item The polynomial characteristic of $A$ is
\[
p(\lambda) =
\left\vert\begin{array}{rrr}
-1-\lambda&-1&1\\
0&-2-\lambda &1\\
0& 0&-1-\lambda\\
 \end{array}\right\vert = (-1 -\lambda)^2(-2 - \lambda).
\]
So $-1$ is an eigenvalue with multiplicity $2$ and $-2$ with multiplicity $1$.
  \item In order to find out whether $A$ is diagonalizable, we only concentrate our attention on the eigenvalue $-1$. Indeed, the eigenvectors associated to $-1$, are given by the system
\[
\Big(A + I_n \Big) X = \left(\begin{array}{rrr} 0&-1&1\\ 0&-1&1\\ 0&0&0\\ \end{array}\right) X= {\cal O}.
\]
This system reduces to the equation $-y + z = 0$. Set $x = \alpha$ and $y = \beta$, then we have
\[
X = \left(\begin{array}{r} x\\ y\\ z\\ \end{array}\right)
=\left(\begin{array}{r} \alpha\\ \beta\\ \beta\\ \end{array}\right)
=\alpha\left(\begin{array}{r} 1\\ 0\\ 0\\ \end{array}\right)
+\beta \left(\begin{array}{r} 0\\ 1\\ 1\\ \end{array}\right).
\]
So the geometric multiplicity of $-1$ is $2$ the same as its algebraic multiplicity. Therefore, the matrix $A$ is diagonalizable. In order to find the matrix $P$ we need to find an eigenvector associated to $-2$. The associated system is
\[
\Big(A + 2 I_n \Big) X = \left(\begin{array}{rrr} 1&-1&1\\ 0&0&1\\ 0&0&1\\ \end{array}\right) X= {\cal O}
\]
which reduces to the system
\[
\left\{\begin{array}{rrr} x-y&=& 0\\ z&=&0\\ \end{array}\right.
\]
Set $x = \alpha$, then we have
\[
X = \left(\begin{array}{r} x\\ y\\ z\\ \end{array}\right)
=\left(\begin{array}{r} \alpha\\ \alpha\\ 0\\ \end{array}\right)
=\alpha \left(\begin{array}{r} 1\\ 1\\ 0\\ \end{array}\right).
\]
Set
\[
P = \left(\begin{array}{rrr} 1&0&1\\ 0&1&1\\ 0&1&0\\ \end{array}\right).
\]
Then
\[
P^{-1}AP = \left(\begin{array}{rrr} -1&0&0\\ 0&-1&0\\ 0&0&-2\\ \end{array}\right).
\]
But if we set
\[
P = \left(\begin{array}{rrr} 1&0&1\\ 1&1&0\\ 0&1&0\\ \end{array}\right),
\]
then
\[
P^{-1}AP = \left(\begin{array}{rrr} -2&0&0\\ 0&-1&0\\ 0&0&-1\\ \end{array}\right).
\]
\end{enumerate} 
We have seen that if $A$ and $B$ are similar, then $A^n$ can be expressed easily in terms of $B^n$. Indeed, if we have $A = P^{-1}BP$, then we have $A^n = P^{-1}B^nP$. In particular, if $D$ is a diagonal matrix, $D^n$ is easy to evaluate. This is one application of the diagonalization. In fact, the above procedure may be used to find the square root and cubic root of a matrix. Indeed, consider the matrix above
\[
A = A = \left(\begin{array}{rrr} -1&-1&1\\ 0&-2&1\\ 0&0&-1\\ \end{array}\right).
\]
Set
\[
P = \left(\begin{array}{rrr} 1&0&1\\ 1&1&0\\ 0&1&0\\ \end{array}\right),
\]
then
\[
P^{-1}AP = \left(\begin{array}{rrr} -2&0&0\\ 0&-1&0\\ 0&0&-1\\ \end{array}\right)=D.
\]
Hence $A = P D P^{-1}$. Set
\[
B = P \left(\begin{array}{rrr} -2^{1/3}&0&0\\ 0&-1&0\\ 0&0&-1\\ \end{array}\right) P^{-1},
\]
Then we have
\[B^3 = A.\]
In other words, $B$ is a cubic root of $A$.
\end{exmp}

\end{document}
